"""
ê³ ê¸‰ ë¸Œëœì¹­ ì„œë¹„ìŠ¤ - ì§€ëŠ¥ì ì¸ ëŒ€í™” ë¶„ê¸° ê´€ë¦¬
"""
from typing import List, Dict, Any, Optional, Tuple
import json
import logging
from datetime import datetime, timezone
from enum import Enum

from backend.db.falkordb import FalkorDBManager
from backend.services.gemini_service import GeminiService
from backend.services.node_service import NodeService
from backend.services.message_service import MessageService
from backend.schemas.node import NodeCreate
from backend.schemas.message import MessageCreate

logger = logging.getLogger(__name__)


class BranchType(Enum):
    """ë¸Œëœì¹˜ ìœ í˜•"""
    TOPIC = "topic"  # ì£¼ì œ ë¶„ê¸°
    DETAIL = "detail"  # ì„¸ë¶€ì‚¬í•­ ë¶„ê¸°
    ALTERNATIVE = "alternative"  # ëŒ€ì•ˆ íƒìƒ‰
    QUESTION = "question"  # ì¶”ê°€ ì§ˆë¬¸
    EXAMPLE = "example"  # ì˜ˆì‹œ íƒêµ¬


class BranchingService:
    """ê³ ê¸‰ ë¸Œëœì¹­ ë¡œì§ì„ ë‹´ë‹¹í•˜ëŠ” ì„œë¹„ìŠ¤"""
    
    def __init__(self, 
                 db: FalkorDBManager, 
                 gemini_service: Optional[GeminiService] = None,
                 google_api_key: Optional[str] = None, 
                 gemini_model: str = "gemini-2.0-flash-exp"):
        self.db = db
        
        # GeminiService ì£¼ì… ë˜ëŠ” ìƒì„±
        if gemini_service:
            self.gemini = gemini_service
            logger.info("ğŸ”µ BranchingService: GeminiServiceê°€ ì£¼ì…ë¨")
        else:
            logger.info(f"ğŸ”´ BranchingService: GeminiServiceë¥¼ ì§ì ‘ ìƒì„±")
            self.gemini = GeminiService(api_key=google_api_key, model=gemini_model)
        
        self.node_service = NodeService(db)
        self.message_service = MessageService(db)
        
        # ë¸Œëœì¹­ ì„ê³„ê°’
        self.complexity_threshold = 0.7  # ë³µì¡ë„ ì„ê³„ê°’
        self.max_branches_per_node = 3  # ë…¸ë“œë‹¹ ìµœëŒ€ ë¸Œëœì¹˜ ìˆ˜
        self.min_context_length = 100  # ìµœì†Œ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´
    
    async def analyze_branching_potential(
        self,
        user_message: str,
        ai_response: str,
        conversation_history: List[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """ëŒ€í™”ì˜ ë¶„ê¸° ì ì¬ë ¥ ë¶„ì„ - ë‹¨ì¼ API í˜¸ì¶œë¡œ ìµœì í™”"""
        try:
            # ì „ì²´ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context = self._build_context(user_message, ai_response, conversation_history)
            
            # ë‹¨ì¼ í†µí•© ë¶„ì„ API í˜¸ì¶œ
            analysis = await self._comprehensive_analysis(context)
            
            # ë¶„ì„ ê²°ê³¼ íŒŒì‹±
            complexity_score = analysis.get("complexity_score", 0)
            branch_types = analysis.get("branch_types", {})
            
            # ì¶”ì²œ ë¸Œëœì¹˜ ìƒì„± (API í˜¸ì¶œ ì—†ì´ ë¡œì»¬ì—ì„œ ì²˜ë¦¬)
            recommended_branches = self._create_recommendations_from_analysis(
                branch_types, 
                complexity_score
            )
            
            return {
                "complexity_score": complexity_score,
                "should_branch": complexity_score >= self.complexity_threshold,
                "branch_analysis": branch_types,
                "recommended_branches": recommended_branches,
                "reasoning": self._generate_reasoning(complexity_score, branch_types)
            }
            
        except Exception as e:
            logger.error(f"ë¸Œëœì¹­ ì ì¬ë ¥ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "complexity_score": 0,
                "should_branch": False,
                "branch_analysis": {},
                "recommended_branches": [],
                "reasoning": "ë¶„ì„ ì‹¤íŒ¨"
            }
    
    async def _comprehensive_analysis(self, context: str) -> Dict[str, Any]:
        """ë‹¨ì¼ API í˜¸ì¶œë¡œ ëª¨ë“  ë¶„ì„ ìˆ˜í–‰ - Structured Output ì‚¬ìš©"""
        try:
            # êµ¬ì¡°í™”ëœ ì¶œë ¥ì„ ìœ„í•œ JSON Schema ì •ì˜
            response_format = {
                "type": "json_schema",
                "json_schema": {
                    "name": "branch_analysis",
                    "strict": True,
                    "schema": {
                        "type": "object",
                        "properties": {
                            "complexity_score": {
                                "type": "number",
                                "description": "ëŒ€í™”ì˜ ë³µì¡ë„ ì ìˆ˜ (0.0~1.0)",
                                "minimum": 0.0,
                                "maximum": 1.0
                            },
                            "branch_types": {
                                "type": "object",
                                "properties": {
                                    "topics": {
                                        "type": "array",
                                        "items": {
                                            "type": "object",
                                            "properties": {
                                                "title": {"type": "string"},
                                                "edge_label": {"type": "string", "maxLength": 10}
                                            },
                                            "required": ["title", "edge_label"],
                                            "additionalProperties": False
                                        },
                                        "maxItems": 2,
                                        "description": "í•µì‹¬ ì£¼ì œë“¤"
                                    },
                                    "details": {
                                        "type": "array",
                                        "items": {
                                            "type": "object",
                                            "properties": {
                                                "title": {"type": "string"},
                                                "edge_label": {"type": "string", "maxLength": 10}
                                            },
                                            "required": ["title", "edge_label"],
                                            "additionalProperties": False
                                        },
                                        "maxItems": 2,
                                        "description": "ì„¸ë¶€ ì„¤ëª…ì´ í•„ìš”í•œ ë¶€ë¶„"
                                    },
                                    "alternatives": {
                                        "type": "array",
                                        "items": {
                                            "type": "object",
                                            "properties": {
                                                "title": {"type": "string"},
                                                "edge_label": {"type": "string", "maxLength": 10}
                                            },
                                            "required": ["title", "edge_label"],
                                            "additionalProperties": False
                                        },
                                        "maxItems": 1,
                                        "description": "ëŒ€ì•ˆì  ì ‘ê·¼ë²•"
                                    },
                                    "questions": {
                                        "type": "array",
                                        "items": {
                                            "type": "object",
                                            "properties": {
                                                "title": {"type": "string"},
                                                "edge_label": {"type": "string", "maxLength": 10}
                                            },
                                            "required": ["title", "edge_label"],
                                            "additionalProperties": False
                                        },
                                        "maxItems": 2,
                                        "description": "ì¶”ê°€ íƒêµ¬ ì§ˆë¬¸"
                                    },
                                    "examples": {
                                        "type": "array",
                                        "items": {
                                            "type": "object",
                                            "properties": {
                                                "title": {"type": "string"},
                                                "edge_label": {"type": "string", "maxLength": 10}
                                            },
                                            "required": ["title", "edge_label"],
                                            "additionalProperties": False
                                        },
                                        "maxItems": 1,
                                        "description": "êµ¬ì²´ì  ì˜ˆì‹œ"
                                    }
                                },
                                "required": ["topics", "details", "alternatives", "questions", "examples"],
                                "additionalProperties": False
                            }
                        },
                        "required": ["complexity_score", "branch_types"],
                        "additionalProperties": False
                    }
                }
            }
            
            prompt = f"""
            ë‹¤ìŒ ëŒ€í™”ë¥¼ ë¶„ì„í•˜ì„¸ìš”:

            ëŒ€í™”:
            {context}

            í‰ê°€ ê¸°ì¤€:
            - complexity_score: ë‹¨ìˆœ(0.0-0.3), ì¤‘ê°„(0.4-0.6), ë³µì¡(0.7-1.0)
            - ì£¼ì œ ìˆ˜, ê¸°ìˆ ì  ê¹Šì´, ì¶”ê°€ íƒêµ¬ í•„ìš”ì„±ì„ ê³ ë ¤
            - ê° ë¸Œëœì¹˜ ì¹´í…Œê³ ë¦¬ëŠ” ì •ë§ í•„ìš”í•œ ê²½ìš°ë§Œ í¬í•¨
            - ë¹ˆ ì¹´í…Œê³ ë¦¬ëŠ” ë¹ˆ ë°°ì—´ë¡œ í‘œì‹œ
            
            ì¤‘ìš”: ê° ë¸Œëœì¹˜ì— ëŒ€í•´:
            - title: ë¸Œëœì¹˜ì˜ ì™„ì „í•œ ì„¤ëª… (ì˜ˆ: "AI ìœ¤ë¦¬ì˜ ì‹¤ì œ ì ìš© ì‚¬ë¡€")
            - edge_label: 10ì ì´ë‚´ì˜ ì§§ì€ ë¼ë²¨ (ì˜ˆ: "ìœ¤ë¦¬ì‚¬ë¡€")
            """
            
            response = await self.gemini.chat_completion(
                messages=[
                    {"role": "system", "content": "ëŒ€í™”ë¥¼ ë¶„ì„í•˜ê³  ë¸Œëœì¹˜ ê°€ëŠ¥ì„±ì„ í‰ê°€í•˜ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                structured=False
            )
            
            if response and "choices" in response:
                try:
                    content = response["choices"][0]["message"]["content"]
                    
                    # Structured Outputì€ ì´ë¯¸ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜ë¨
                    # í•˜ì§€ë§Œ DeepSeekì´ êµ¬ì¡°í™” ì¶œë ¥ì„ ì§€ì›í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ fallback ì²˜ë¦¬
                    if isinstance(content, str):
                        # JSON ì¶”ì¶œ (êµ¬ì¡°í™” ì¶œë ¥ì´ ì‘ë™í•˜ì§€ ì•Šì„ ê²½ìš°)
                        if "```json" in content:
                            content = content.split("```json")[1].split("```")[0]
                        elif "```" in content:
                            content = content.split("```")[1].split("```")[0]
                        
                        analysis = json.loads(content.strip())
                    else:
                        analysis = content  # ì´ë¯¸ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš°
                    
                    # ê¸°ë³¸ê°’ ë³´ì¥
                    if "complexity_score" not in analysis:
                        analysis["complexity_score"] = 0.5
                    if "branch_types" not in analysis:
                        analysis["branch_types"] = {}
                    
                    # branch_types ê¸°ë³¸ê°’ ë³´ì¥
                    default_types = {
                        "topics": [],
                        "details": [],
                        "alternatives": [],
                        "questions": [],
                        "examples": []
                    }
                    
                    for key in default_types:
                        if key not in analysis["branch_types"]:
                            analysis["branch_types"][key] = []
                    
                    return analysis
                    
                except (json.JSONDecodeError, Exception) as e:
                    logger.warning(f"í†µí•© ë¶„ì„ íŒŒì‹± ì‹¤íŒ¨: {e}")
            
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                "complexity_score": 0.5,
                "branch_types": {
                    "topics": [],
                    "details": [],
                    "alternatives": [],
                    "questions": [],
                    "examples": []
                }
            }
            
        except Exception as e:
            logger.error(f"í†µí•© ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "complexity_score": 0.0,
                "branch_types": {
                    "topics": [],
                    "details": [],
                    "alternatives": [],
                    "questions": [],
                    "examples": []
                }
            }
    
    def _create_recommendations_from_analysis(
        self,
        branch_types: Dict[str, List[str]],
        complexity_score: float
    ) -> List[Dict[str, Any]]:
        """ë¶„ì„ ê²°ê³¼ë¡œë¶€í„° ì¶”ì²œ ë¸Œëœì¹˜ ìƒì„± (API í˜¸ì¶œ ì—†ìŒ)"""
        recommendations = []
        
        # ë³µì¡ë„ì— ë”°ë¼ ìµœëŒ€ ë¸Œëœì¹˜ ìˆ˜ ê²°ì •
        max_branches = min(
            int(complexity_score * 5),
            self.max_branches_per_node
        )
        
        # ìš°ì„ ìˆœìœ„ ìˆœì„œ
        priority_order = ["topics", "details", "questions", "alternatives", "examples"]
        
        for branch_type in priority_order:
            if len(recommendations) >= max_branches:
                break
            
            branches = branch_types.get(branch_type, [])
            for branch_item in branches:
                if len(recommendations) >= max_branches:
                    break
                
                # branch_itemì´ ë”•ì…”ë„ˆë¦¬ì¸ì§€ ë¬¸ìì—´ì¸ì§€ í™•ì¸
                if isinstance(branch_item, dict):
                    branch_title = branch_item.get("title", "")
                    edge_label = branch_item.get("edge_label", "")
                else:
                    # êµ¬ë²„ì „ í˜¸í™˜ì„±ì„ ìœ„í•œ í´ë°±
                    branch_title = str(branch_item)
                    edge_label = ""
                
                if not branch_title:
                    continue
                
                # ë¡œì»¬ì—ì„œ ì„¤ëª… ìƒì„± (API í˜¸ì¶œ ì—†ìŒ)
                type_descriptions = {
                    "topics": "ì£¼ì œë¥¼ ê¹Šì´ íƒêµ¬",
                    "details": "ì„¸ë¶€ì‚¬í•­ì„ ìì„¸íˆ ì„¤ëª…",
                    "alternatives": "ëŒ€ì•ˆì  ì ‘ê·¼ ë°©ì‹ íƒìƒ‰",
                    "questions": "ì¶”ê°€ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€",
                    "examples": "êµ¬ì²´ì ì¸ ì˜ˆì‹œ ì œê³µ"
                }
                
                description = f"'{branch_title}'ì— ëŒ€í•´ {type_descriptions.get(branch_type, 'ì¶”ê°€ íƒêµ¬')}í•©ë‹ˆë‹¤."
                
                # edge_labelì´ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìœ¼ë©´ ìƒì„±
                if not edge_label:
                    # ê¸°ë³¸ ë¼ë²¨ ìƒì„± (10ì ì´ë‚´)
                    edge_labels = {
                        "topics": ["ì£¼ì œíƒêµ¬", "í•µì‹¬ë¶„ì„", "ê°œë…ì •ë¦¬"],
                        "details": ["ìƒì„¸ì„¤ëª…", "ê¹Šì´íƒêµ¬", "ì„¸ë¶€ë¶„ì„"],
                        "alternatives": ["ëŒ€ì•ˆê²€í† ", "ë‹¤ë¥¸ë°©ë²•", "ìƒˆë¡œìš´ì‹œê°"],
                        "questions": ["ì§ˆë¬¸ë‹µë³€", "ê¶ê¸ˆì¦í•´ê²°", "ì¶”ê°€ì§ˆë¬¸"],
                        "examples": ["ì˜ˆì‹œì œê³µ", "ì‹¤ì œì‚¬ë¡€", "êµ¬ì²´ì˜ˆì‹œ"]
                    }
                    
                    # branch_titleì˜ ì²« 2-3ë‹¨ì–´ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜ ê¸°ë³¸ ë¼ë²¨ ì‚¬ìš©
                    title_words = branch_title.split()[:2]
                    if len(''.join(title_words)) <= 10:
                        edge_label = ' '.join(title_words)
                    else:
                        # íƒ€ì…ë³„ ê¸°ë³¸ ë¼ë²¨ ì„ íƒ
                        labels = edge_labels.get(branch_type, ["íƒêµ¬"])
                        import random
                        edge_label = random.choice(labels)
                
                recommendations.append({
                    "title": branch_title,
                    "type": branch_type,
                    "description": description,
                    "priority": self._calculate_priority(branch_type, complexity_score),
                    "estimated_depth": self._estimate_depth(branch_type),
                    "edge_label": edge_label  # ì—£ì§€ ë¼ë²¨ ì¶”ê°€
                })
        
        # ìš°ì„ ìˆœìœ„ë¡œ ì •ë ¬
        recommendations.sort(key=lambda x: x["priority"], reverse=True)
        
        return recommendations[:max_branches]
    
    async def _evaluate_complexity(self, context: str) -> float:
        """ëŒ€í™” ë³µì¡ë„ í‰ê°€ (0~1)"""
        try:
            prompt = f"""
            ë‹¤ìŒ ëŒ€í™”ì˜ ë³µì¡ë„ë¥¼ 0ì—ì„œ 1 ì‚¬ì´ì˜ ìˆ«ìë¡œ í‰ê°€í•˜ì„¸ìš”.
            
            í‰ê°€ ê¸°ì¤€:
            - ë‹¤ë£¨ëŠ” ì£¼ì œì˜ ìˆ˜
            - ê°œë…ì˜ ê¹Šì´
            - ê¸°ìˆ ì  ë³µì¡ì„±
            - ì¶”ê°€ íƒêµ¬ í•„ìš”ì„±
            
            ëŒ€í™”:
            {context}
            
            ìˆ«ìë§Œ ë°˜í™˜í•˜ì„¸ìš” (ì˜ˆ: 0.7)
            """
            
            response = await self.gemini.chat_completion(
                messages=[
                    {"role": "system", "content": "ë³µì¡ë„ë¥¼ 0~1 ì‚¬ì´ ìˆ«ìë¡œë§Œ ë°˜í™˜í•˜ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                structured=False
            )
            
            if response and "choices" in response:
                try:
                    score_str = response["choices"][0]["message"]["content"].strip()
                    score = float(score_str)
                    return min(max(score, 0), 1)  # 0~1 ë²”ìœ„ë¡œ ì œí•œ
                except (ValueError, IndexError):
                    return 0.5  # ê¸°ë³¸ê°’
            
            return 0.5
            
        except Exception as e:
            logger.error(f"ë³µì¡ë„ í‰ê°€ ì‹¤íŒ¨: {e}")
            return 0.5
    
    async def _analyze_branch_types(self, context: str) -> Dict[str, List[str]]:
        """ë¸Œëœì¹˜ ìœ í˜•ë³„ ë¶„ì„"""
        try:
            prompt = f"""
            ë‹¤ìŒ ëŒ€í™”ì—ì„œ ê° ìœ í˜•ë³„ë¡œ íƒêµ¬í•  ìˆ˜ ìˆëŠ” ì£¼ì œë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.
            
            ëŒ€í™”:
            {context}
            
            ë‹¤ìŒ í˜•ì‹ì˜ JSONìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:
            {{
                "topics": ["ì£¼ìš” ì£¼ì œ1", "ì£¼ìš” ì£¼ì œ2"],
                "details": ["ì„¸ë¶€ì‚¬í•­1", "ì„¸ë¶€ì‚¬í•­2"],
                "alternatives": ["ëŒ€ì•ˆ1", "ëŒ€ì•ˆ2"],
                "questions": ["ì¶”ê°€ ì§ˆë¬¸1", "ì¶”ê°€ ì§ˆë¬¸2"],
                "examples": ["ì˜ˆì‹œ íƒêµ¬1", "ì˜ˆì‹œ íƒêµ¬2"]
            }}
            
            ê° ì¹´í…Œê³ ë¦¬ëŠ” ìµœëŒ€ 2ê°œê¹Œì§€ë§Œ, ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´
            """
            
            response = await self.gemini.chat_completion(
                messages=[
                    {"role": "system", "content": "JSON í˜•ì‹ìœ¼ë¡œë§Œ ë°˜í™˜í•˜ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                structured=False
            )
            
            if response and "choices" in response:
                try:
                    content = response["choices"][0]["message"]["content"]
                    
                    # JSON ì¶”ì¶œ
                    if "```json" in content:
                        content = content.split("```json")[1].split("```")[0]
                    elif "```" in content:
                        content = content.split("```")[1].split("```")[0]
                    
                    analysis = json.loads(content.strip())
                    
                    # ê¸°ë³¸ êµ¬ì¡° ë³´ì¥
                    default = {
                        "topics": [],
                        "details": [],
                        "alternatives": [],
                        "questions": [],
                        "examples": []
                    }
                    
                    for key in default:
                        if key not in analysis or not isinstance(analysis[key], list):
                            analysis[key] = []
                    
                    return analysis
                    
                except (json.JSONDecodeError, Exception) as e:
                    logger.warning(f"ë¸Œëœì¹˜ ìœ í˜• ë¶„ì„ íŒŒì‹± ì‹¤íŒ¨: {e}")
                    
            return {
                "topics": [],
                "details": [],
                "alternatives": [],
                "questions": [],
                "examples": []
            }
            
        except Exception as e:
            logger.error(f"ë¸Œëœì¹˜ ìœ í˜• ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}
    
    async def _generate_branch_recommendations(
        self,
        context: str,
        branch_analysis: Dict[str, List[str]],
        complexity_score: float
    ) -> List[Dict[str, Any]]:
        """ì¶”ì²œ ë¸Œëœì¹˜ ìƒì„±"""
        recommendations = []
        
        try:
            # ë³µì¡ë„ì— ë”°ë¼ ë¸Œëœì¹˜ ìˆ˜ ì¡°ì •
            max_branches = min(
                int(complexity_score * 5),  # ë³µì¡ë„ì— ë¹„ë¡€
                self.max_branches_per_node
            )
            
            # ìš°ì„ ìˆœìœ„: topics > details > questions > alternatives > examples
            priority_order = ["topics", "details", "questions", "alternatives", "examples"]
            
            for branch_type in priority_order:
                if len(recommendations) >= max_branches:
                    break
                    
                branches = branch_analysis.get(branch_type, [])
                for branch_title in branches:
                    if len(recommendations) >= max_branches:
                        break
                    
                    # ë¸Œëœì¹˜ ì„¤ëª… ìƒì„±
                    description = await self._generate_branch_description(
                        branch_title,
                        branch_type,
                        context
                    )
                    
                    recommendations.append({
                        "title": branch_title,
                        "type": branch_type,
                        "description": description,
                        "priority": self._calculate_priority(branch_type, complexity_score),
                        "estimated_depth": self._estimate_depth(branch_type)
                    })
            
            # ìš°ì„ ìˆœìœ„ë¡œ ì •ë ¬
            recommendations.sort(key=lambda x: x["priority"], reverse=True)
            
            return recommendations[:max_branches]
            
        except Exception as e:
            logger.error(f"ë¸Œëœì¹˜ ì¶”ì²œ ìƒì„± ì‹¤íŒ¨: {e}")
            return []
    
    async def _generate_branch_description(
        self,
        title: str,
        branch_type: str,
        context: str
    ) -> str:
        """ë¸Œëœì¹˜ ì„¤ëª… ìƒì„±"""
        try:
            type_descriptions = {
                "topics": "ì£¼ì œë¥¼ ê¹Šì´ íƒêµ¬",
                "details": "ì„¸ë¶€ì‚¬í•­ì„ ìì„¸íˆ ì„¤ëª…",
                "alternatives": "ëŒ€ì•ˆì  ì ‘ê·¼ ë°©ì‹ íƒìƒ‰",
                "questions": "ì¶”ê°€ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€",
                "examples": "êµ¬ì²´ì ì¸ ì˜ˆì‹œ ì œê³µ"
            }
            
            base_description = type_descriptions.get(branch_type, "ì¶”ê°€ íƒêµ¬")
            return f"'{title}'ì— ëŒ€í•´ {base_description}í•©ë‹ˆë‹¤."
            
        except Exception as e:
            logger.error(f"ë¸Œëœì¹˜ ì„¤ëª… ìƒì„± ì‹¤íŒ¨: {e}")
            return f"'{title}'ì— ëŒ€í•´ ë” ìì„¸íˆ íƒêµ¬í•©ë‹ˆë‹¤."
    
    async def create_smart_branches(
        self,
        parent_node_id: str,
        recommendations: List[Dict[str, Any]],
        auto_approve: bool = False
    ) -> List[Dict[str, Any]]:
        """ìŠ¤ë§ˆíŠ¸ ë¸Œëœì¹˜ ìƒì„±"""
        created_branches = []
        
        try:
            # ë¶€ëª¨ ë…¸ë“œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            parent_node = await self.node_service.get_node(parent_node_id)
            if not parent_node:
                logger.error(f"ë¶€ëª¨ ë…¸ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {parent_node_id}")
                return []
            
            # parent_nodeê°€ Pydantic ëª¨ë¸ì¸ì§€ dictì¸ì§€ í™•ì¸
            if hasattr(parent_node, 'session_id'):
                session_id = parent_node.session_id
            else:
                session_id = parent_node["session_id"]
            
            for recommendation in recommendations:
                if not auto_approve and recommendation["priority"] < 0.5:
                    continue  # ìš°ì„ ìˆœìœ„ê°€ ë‚®ìœ¼ë©´ ìë™ ìŠ¹ì¸ ëª¨ë“œê°€ ì•„ë‹ ë•Œ ê±´ë„ˆëœ€
                
                try:
                    # ë¸Œëœì¹˜ ë…¸ë“œ ìƒì„±
                    # recommendationì—ì„œ node_type í•„ë“œ í™•ì¸, ì—†ìœ¼ë©´ 'topic' ì‚¬ìš©
                    # type ë§¤í•‘: branch_typeì„ node_typeìœ¼ë¡œ ë³€í™˜
                    branch_type = recommendation.get("type", "topics")
                    node_type_mapping = {
                        "topics": "topic",
                        "details": "exploration",
                        "alternatives": "exploration",
                        "questions": "question",
                        "examples": "exploration"
                    }
                    node_type = recommendation.get("node_type", node_type_mapping.get(branch_type, "topic"))
                    
                    branch_node = await self.node_service.create_node(
                        session_id=session_id,
                        node_data=NodeCreate(
                            session_id=session_id,
                            parent_id=parent_node_id,
                            title=recommendation["title"],
                            content=recommendation.get("description", ""),
                            type=node_type,
                            metadata={
                                "branch_type": recommendation.get("type", "topics"),
                                "priority": recommendation.get("priority", 0.5),
                                "estimated_depth": recommendation.get("estimated_depth", 3),
                                "auto_generated": True,
                                "created_at": datetime.now(timezone.utc).isoformat()
                            }
                        )
                    )
                    
                    if branch_node:
                        # WebSocketì„ í†µí•´ ë…¸ë“œ ìƒì„± ì´ë²¤íŠ¸ ë¸Œë¡œë“œìºìŠ¤íŠ¸
                        from backend.api.websocket.connection_manager import connection_manager
                        
                        # branch_nodeê°€ Pydantic ëª¨ë¸ì¸ì§€ dictì¸ì§€ í™•ì¸
                        if hasattr(branch_node, 'id'):
                            node_id = branch_node.id
                            # Pydantic ëª¨ë¸ì„ dictë¡œ ë³€í™˜
                            branch_dict = branch_node.model_dump() if hasattr(branch_node, 'model_dump') else branch_node.dict()
                        else:
                            node_id = branch_node["id"]
                            branch_dict = branch_node
                        
                        # WebSocket ì´ë²¤íŠ¸ ì „ì†¡
                        node_event = {
                            "type": "node_created",
                            "session_id": session_id,
                            "node": branch_dict,
                            "parent_id": parent_node_id
                        }
                        logger.info(f"[ë¸Œëœì¹˜ ìƒì„±] WebSocket ì´ë²¤íŠ¸ ì „ì†¡ ì¤€ë¹„: node_id={node_id}, parent_id={parent_node_id}, session_id={session_id}")
                        await connection_manager.broadcast(node_event, session_id)
                        logger.info(f"[ë¸Œëœì¹˜ ìƒì„±] WebSocket ì´ë²¤íŠ¸ ì „ì†¡ ì™„ë£Œ: {node_event['type']}")
                        
                        # ì´ˆê¸° ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì¶”ê°€
                        await self.message_service.create_message(
                            MessageCreate(
                                node_id=node_id,
                                content=f"ì´ ë¸Œëœì¹˜ëŠ” '{recommendation['title']}'ì— ëŒ€í•´ íƒêµ¬í•©ë‹ˆë‹¤. {recommendation.get('description', '')}",
                                role="system"
                            )
                        )
                        
                        created_branches.append(branch_dict)
                        logger.info(f"[ë¸Œëœì¹˜ ìƒì„±] ìŠ¤ë§ˆíŠ¸ ë¸Œëœì¹˜ ìƒì„± ì™„ë£Œ: {recommendation['title']}, node_id={node_id}")
                        
                except Exception as e:
                    logger.error(f"ë¸Œëœì¹˜ ìƒì„± ì‹¤íŒ¨: {recommendation['title']}, ì˜¤ë¥˜: {e}")
                    continue
            
            return created_branches
            
        except Exception as e:
            logger.error(f"ìŠ¤ë§ˆíŠ¸ ë¸Œëœì¹˜ ìƒì„± ì‹¤íŒ¨: {e}")
            return []
    
    def _build_context(
        self,
        user_message: str,
        ai_response: str,
        history: List[Dict[str, Any]] = None
    ) -> str:
        """ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
        context_parts = []
        
        if history:
            for msg in history[-5:]:  # ìµœê·¼ 5ê°œ ë©”ì‹œì§€
                role = msg.get("role", "user")
                content = msg.get("content", "")
                context_parts.append(f"{role}: {content}")
        
        context_parts.append(f"ì‚¬ìš©ì: {user_message}")
        context_parts.append(f"AI: {ai_response}")
        
        return "\n\n".join(context_parts)
    
    def _calculate_priority(self, branch_type: str, complexity_score: float) -> float:
        """ë¸Œëœì¹˜ ìš°ì„ ìˆœìœ„ ê³„ì‚°"""
        type_weights = {
            "topics": 0.9,
            "details": 0.7,
            "questions": 0.6,
            "alternatives": 0.5,
            "examples": 0.4
        }
        
        base_priority = type_weights.get(branch_type, 0.3)
        return base_priority * complexity_score
    
    def _estimate_depth(self, branch_type: str) -> int:
        """ì˜ˆìƒ ê¹Šì´ ì¶”ì •"""
        depth_map = {
            "topics": 5,
            "details": 3,
            "questions": 2,
            "alternatives": 4,
            "examples": 2
        }
        
        return depth_map.get(branch_type, 3)
    
    def _generate_reasoning(
        self,
        complexity_score: float,
        branch_analysis: Dict[str, List[str]]
    ) -> str:
        """ë¶„ê¸° ì¶”ì²œ ì´ìœ  ìƒì„±"""
        total_branches = sum(len(v) for v in branch_analysis.values())
        
        if complexity_score >= 0.8:
            return f"ë§¤ìš° ë³µì¡í•œ ì£¼ì œë¡œ {total_branches}ê°œì˜ ì ì¬ì  ë¶„ê¸°ì ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤."
        elif complexity_score >= 0.6:
            return f"ì¤‘ê°„ ë³µì¡ë„ì˜ ì£¼ì œë¡œ {total_branches}ê°œì˜ íƒêµ¬ ê°€ëŠ¥í•œ ë°©í–¥ì´ ìˆìŠµë‹ˆë‹¤."
        elif complexity_score >= 0.4:
            return f"ì¼ë¶€ ì¶”ê°€ íƒêµ¬ê°€ ê°€ëŠ¥í•œ {total_branches}ê°œì˜ í•˜ìœ„ ì£¼ì œê°€ ìˆìŠµë‹ˆë‹¤."
        else:
            return "ë‹¨ìˆœí•œ ì£¼ì œë¡œ ë¶„ê¸°ê°€ í•„ìš”í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    
    async def summarize_messages(self, messages: List[Any]) -> str:
        """ë©”ì‹œì§€ ëª©ë¡ì„ ìš”ì•½"""
        try:
            # ë©”ì‹œì§€ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (Message ê°ì²´ë§Œ ì²˜ë¦¬)
            conversation_parts = []
            for msg in messages:
                # Message ê°ì²´ì¸ ê²½ìš°ë§Œ ì²˜ë¦¬
                if hasattr(msg, 'role') and hasattr(msg, 'content'):
                    conversation_parts.append(f"{msg.role}: {msg.content}")
                else:
                    logger.warning(f"Expected Message object, got: {type(msg)}")
            
            if not conversation_parts:
                return "ëŒ€í™” ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."
            
            conversation = "\n".join(conversation_parts)
            
            # ëŒ€í™” ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ ìš”ì•½í•˜ì§€ ì•ŠìŒ
            if len(conversation) < 100:
                return conversation[:200] if len(conversation) > 200 else conversation
            
            prompt = f"""
            ë‹¤ìŒ ëŒ€í™”ë¥¼ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”. í•µì‹¬ ì£¼ì œì™€ ì¤‘ìš”í•œ ê²°ì •ì‚¬í•­ì„ í¬í•¨í•´ì£¼ì„¸ìš”.
            
            ëŒ€í™”:
            {conversation[:2000]}  # ë„ˆë¬´ ê¸´ ëŒ€í™”ëŠ” ì˜ë¼ì„œ ì „ì†¡
            
            ìš”ì•½ (3-5ë¬¸ì¥):
            """
            
            # Gemini API ì§ì ‘ í˜¸ì¶œ (mock_mode ì²´í¬ ì—†ìŒ - GeminiServiceì—ì„œ ì²˜ë¦¬)
            response = await self.gemini.chat_completion(
                messages=[
                    {"role": "system", "content": "ëŒ€í™”ë¥¼ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ìš”ì•½í•˜ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3
            )
            
            # ChatResponse ê°ì²´ì—ì„œ content ì¶”ì¶œ
            if response and hasattr(response, 'content'):
                summary = response.content
                # ìš”ì•½ì´ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ì„œ ë°˜í™˜
                return summary[:500] if len(summary) > 500 else summary
            else:
                return "ì´ì „ ëŒ€í™”ê°€ ìˆìŠµë‹ˆë‹¤."
                
        except Exception as e:
            logger.error(f"ë©”ì‹œì§€ ìš”ì•½ ì‹¤íŒ¨: {e}")
            return "ì´ì „ ëŒ€í™”ê°€ ìˆìŠµë‹ˆë‹¤."
    
    async def check_context_limit(
        self,
        node_id: str,
        token_limit: int = 4000
    ) -> Tuple[bool, int, Optional[str]]:
        """ì»¨í…ìŠ¤íŠ¸ í•œê³„ í™•ì¸ ë° ìš”ì•½ í•„ìš”ì„± íŒë‹¨"""
        try:
            # ë…¸ë“œì˜ ì „ì²´ ëŒ€í™” ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°
            conversation = await self.message_service.get_conversation_history(node_id)
            
            # ConversationHistory ê°ì²´ì—ì„œ messages ì¶”ì¶œ
            if hasattr(conversation, 'messages'):
                history = conversation.messages
            else:
                history = conversation if isinstance(conversation, list) else []
            
            # í† í° ìˆ˜ ì¶”ì • (ê°„ë‹¨í•œ ë°©ë²•: ë¬¸ì ìˆ˜ / 4)
            total_chars = 0
            for msg in history:
                if hasattr(msg, 'content'):
                    total_chars += len(msg.content)
                elif isinstance(msg, dict):
                    total_chars += len(msg.get("content", ""))
            estimated_tokens = total_chars // 4
            
            # í•œê³„ ë„ë‹¬ ì—¬ë¶€
            is_near_limit = estimated_tokens > (token_limit * 0.8)
            
            # ìš”ì•½ì´ í•„ìš”í•œ ê²½ìš° ìš”ì•½ ìƒì„±
            summary = None
            if is_near_limit:
                contents = []
                for msg in history:
                    if hasattr(msg, 'content'):
                        contents.append(msg.content)
                    elif isinstance(msg, dict):
                        contents.append(msg.get("content", ""))
                summary = await self._generate_context_summary(contents)
            
            return is_near_limit, estimated_tokens, summary
            
        except Exception as e:
            logger.error(f"ì»¨í…ìŠ¤íŠ¸ í•œê³„ í™•ì¸ ì‹¤íŒ¨: {e}")
            return False, 0, None
    
    async def _generate_context_summary(self, contents: List[str]) -> str:
        """ì»¨í…ìŠ¤íŠ¸ ìš”ì•½ ìƒì„±"""
        try:
            combined = "\n\n".join(contents[:20])  # ìµœëŒ€ 20ê°œ ë©”ì‹œì§€
            
            prompt = f"""
            ë‹¤ìŒ ëŒ€í™”ë¥¼ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”. í•µì‹¬ ì£¼ì œì™€ ì¤‘ìš”í•œ ê²°ë¡ ë§Œ í¬í•¨í•˜ì„¸ìš”.
            
            ëŒ€í™”:
            {combined[:3000]}  # ìµœëŒ€ 3000ì
            
            200ì ì´ë‚´ë¡œ ìš”ì•½í•˜ì„¸ìš”.
            """
            
            response = await self.gemini.chat_completion(
                messages=[
                    {"role": "system", "content": "ê°„ê²°í•˜ê³  í•µì‹¬ì ì¸ ìš”ì•½ì„ ì œê³µí•˜ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                structured=False
            )
            
            if response and "choices" in response:
                return response["choices"][0]["message"]["content"]
            
            return "ëŒ€í™” ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
        except Exception as e:
            logger.error(f"ì»¨í…ìŠ¤íŠ¸ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
            return "ìš”ì•½ ìƒì„± ì‹¤íŒ¨"