import { Node, Branch, EdgeLabels } from '@/types'

export const generateDummyNodes = (): Node[] => {
  const nodes: Node[] = [
    {
      id: 'root',
      parentId: null,
      title: 'μ‹μ‘',
      description: 'λ€ν™”μ μ‹μ‘μ ',
      type: 'main',
      status: 'completed',
      depth: 0,
      tokenCount: 245,
      summaryContent: 'AI μ¤λ¦¬μ™€ κΈ°μ  κµ¬ν„μ— λ€ν• λ…Όμ μ‹μ‘',
      keyPoints: ['AI μ¤λ¦¬ λ¬Έμ  μ κΈ°', 'κΈ°μ μ  κµ¬ν„ λ°©λ²• νƒκµ¬', 'λ‘ κ°€μ§€ λ°©ν–¥ μ μ‹'],
      createdAt: new Date('2024-01-01T10:00:00'),
      updatedAt: new Date('2024-01-01T10:01:00'),
      messages: [
        {
          id: 'm1',
          content: 'AIμ μ¤λ¦¬μ  λ¬Έμ μ™€ κΈ°μ μ  κµ¬ν„μ— λ€ν•΄ λ…Όμν•κ³  μ‹¶μµλ‹λ‹¤. μ½”λ“ μμ‹μ™€ λ‹¤μ΄μ–΄κ·Έλ¨λ„ λ³΄μ—¬μ£Όμ„Έμ”.',
          role: 'user',
          branchId: 'root',
          timestamp: new Date('2024-01-01T10:00:00'),
        },
        {
          id: 'm2',
          content: getDummyMarkdownContent(),
          role: 'assistant',
          branchId: 'root',
          timestamp: new Date('2024-01-01T10:01:00'),
        },
      ],
    },
    {
      id: 'ethics',
      parentId: 'root',
      title: 'AI μ¤λ¦¬',
      description: 'AIμ μ¤λ¦¬μ  λ¬Έμ μ™€ μ‚¬νμ  μν–¥',
      type: 'topic',
      status: 'active',
      depth: 1,
      color: '#9C27B0',
      tokenCount: 523,
      summaryContent: 'AI μ‹μ¤ν…μ νΈν–¥μ„±, ν¬λ…μ„±, ν”„λΌμ΄λ²„μ‹, μ±…μ„μ†μ¬ λ¬Έμ  λ¶„μ„',
      keyPoints: ['νΈν–¥μ„±κ³Ό κ³µμ •μ„±', 'ν¬λ…μ„±κ³Ό μ„¤λ…κ°€λ¥μ„±', 'ν”„λΌμ΄λ²„μ‹ λ³΄νΈ', 'μ±…μ„μ†μ¬ λ…ν™•ν™”'],
      createdAt: new Date('2024-01-01T10:02:00'),
      updatedAt: new Date('2024-01-01T10:03:00'),
      charts: [
        {
          type: 'list',
          content: ['νΈν–¥μ„± λ¬Έμ ', 'ν¬λ…μ„± λ¬Έμ ', 'ν”„λΌμ΄λ²„μ‹', 'μ±…μ„μ†μ¬']
        }
      ],
      messages: [
        {
          id: 'm3',
          content: 'AI μ¤λ¦¬μ—μ„ κ°€μ¥ μ¤‘μ”ν• μ΄μλ” λ¬΄μ—‡μΈκ°€μ”?',
          role: 'user',
          branchId: 'ethics',
          timestamp: new Date('2024-01-01T10:02:00'),
        },
        {
          id: 'm4',
          content: 'AI μ¤λ¦¬μ ν•µμ‹¬ μ΄μλ“¤:\n\n1. **νΈν–¥μ„±κ³Ό κ³µμ •μ„±**: AI μ‹μ¤ν…μ΄ ν•™μµ λ°μ΄ν„°μ νΈκ²¬μ„ λ°μ\n2. **ν¬λ…μ„±κ³Ό μ„¤λ…κ°€λ¥μ„±**: AI κ²°μ • κ³Όμ •μ λΈ”λ™λ°•μ¤ λ¬Έμ \n3. **ν”„λΌμ΄λ²„μ‹**: κ°μΈμ •λ³΄ μμ§‘κ³Ό ν™μ©μ κ²½κ³„\n4. **μ±…μ„μ†μ¬**: AI κ²°μ •μ μ±…μ„ κ·€μ† λ¬Έμ ',
          role: 'assistant',
          branchId: 'ethics',
          timestamp: new Date('2024-01-01T10:03:00'),
        },
      ],
    },
    {
      id: 'technical',
      parentId: 'root',
      title: 'κΈ°μ μ  κµ¬ν„',
      description: 'AI μ‹μ¤ν…μ κΈ°μ μ  κµ¬ν„ λ°©λ²•',
      type: 'topic',
      status: 'active',
      depth: 1,
      color: '#4FC3F7',
      tokenCount: 687,
      summaryContent: 'LLM κµ¬ν„μ— ν•„μ”ν• ν•µμ‹¬ κΈ°μ  μ¤νƒκ³Ό μ•„ν‚¤ν…μ²',
      keyPoints: ['Transformer μ•„ν‚¤ν…μ²', 'λ¶„μ‚° ν•™μµ μ‹μ¤ν…', 'ν† ν¬λ‚μ΄μ € κµ¬ν„', 'μµμ ν™” κΈ°λ²•'],
      createdAt: new Date('2024-01-01T10:02:30'),
      updatedAt: new Date('2024-01-01T10:03:30'),
      charts: [
        {
          type: 'flow',
          content: 'Input β†’ Tokenizer β†’ Transformer β†’ Output'
        }
      ],
      messages: [
        {
          id: 'm5',
          content: 'λ€κ·λ¨ μ–Έμ–΄ λ¨λΈμ„ κµ¬ν„ν•λ ¤λ©΄ μ–΄λ–¤ κΈ°μ μ΄ ν•„μ”ν•κ°€μ”?',
          role: 'user',
          branchId: 'technical',
          timestamp: new Date('2024-01-01T10:02:00'),
        },
        {
          id: 'm6',
          content: 'LLM κµ¬ν„μ— ν•„μ”ν• ν•µμ‹¬ κΈ°μ :\n\n1. **Transformer μ•„ν‚¤ν…μ²**: Self-attention λ©”μ»¤λ‹μ¦\n2. **λ¶„μ‚° ν•™μµ**: μ—¬λ¬ GPU/TPUλ¥Ό ν™μ©ν• λ³‘λ ¬ μ²λ¦¬\n3. **ν† ν¬λ‚μ΄μ €**: ν…μ¤νΈλ¥Ό ν† ν°μΌλ΅ λ³€ν™\n4. **μµμ ν™” κΈ°λ²•**: Adam, AdamW λ“±μ μµν‹°λ§μ΄μ €',
          role: 'assistant',
          branchId: 'technical',
          timestamp: new Date('2024-01-01T10:03:00'),
        },
      ],
    },
    {
      id: 'bias',
      parentId: 'ethics',
      title: 'νΈν–¥μ„± λ¬Έμ ',
      description: 'AIμ νΈν–¥μ„±κ³Ό ν•΄κ²° λ°©μ•',
      type: 'question',
      status: 'active',
      depth: 2,
      color: '#FFC107',
      tokenCount: 156,
      summaryContent: 'νΈν–¥μ„± νƒμ§€μ™€ μ™„ν™” λ°©λ²•λ΅ ',
      keyPoints: ['λ°μ΄ν„° νΈν–¥ λ¶„μ„', 'μ•κ³ λ¦¬μ¦ κ³µμ •μ„±', 'ν‰κ°€ λ©”νΈλ¦­'],
      messages: [
        {
          id: 'm7',
          content: 'AIμ νΈν–¥μ„±μ„ μ–΄λ–»κ² νƒμ§€ν•κ³  μ™„ν™”ν•  μ μμ„κΉμ”?',
          role: 'user',
          branchId: 'bias',
          timestamp: new Date('2024-01-01T10:04:00'),
        },
      ],
    },
    {
      id: 'transformer',
      parentId: 'technical',
      title: 'Transformer μ•„ν‚¤ν…μ²',
      description: 'Transformer λ¨λΈμ μ„Έλ¶€ κµ¬ν„',
      type: 'exploration',
      status: 'active',
      depth: 2,
      color: '#4CAF50',
      tokenCount: 234,
      summaryContent: 'Self-attention λ©”μ»¤λ‹μ¦ μƒμ„Έ λ¶„μ„',
      keyPoints: ['Multi-head attention', 'Positional encoding', 'Feed-forward networks'],
      messages: [
        {
          id: 'm8',
          content: 'Self-attention λ©”μ»¤λ‹μ¦μ„ μμ„Έν μ„¤λ…ν•΄μ£Όμ„Έμ”.',
          role: 'user',
          branchId: 'transformer',
          timestamp: new Date('2024-01-01T10:04:00'),
        },
      ],
    },
    {
      id: 'privacy',
      parentId: 'ethics',
      title: 'ν”„λΌμ΄λ²„μ‹',
      description: 'κ°μΈμ •λ³΄ λ³΄νΈμ™€ AI',
      type: 'topic',
      status: 'paused',
      depth: 2,
      color: '#FF5722',
      messages: [],
    },
    {
      id: 'optimization',
      parentId: 'technical',
      title: 'μµμ ν™” κΈ°λ²•',
      description: 'λ¨λΈ ν•™μµ μµμ ν™”',
      type: 'exploration',
      status: 'paused',
      depth: 2,
      color: '#00BCD4',
      messages: [],
    },
    {
      id: 'merge1',
      parentId: null,
      sourceNodeIds: ['bias', 'transformer'],
      title: 'ν†µν•© λ¶„μ„',
      description: 'νΈν–¥μ„±κ³Ό κΈ°μ μ  κµ¬ν„μ κµμ§‘ν•©',
      type: 'summary',
      status: 'active',
      depth: 3,
      color: '#E91E63',
      isSummary: true,
      tokenCount: 892,
      summaryContent: 'κΈ°μ  μ„¤κ³„ λ‹¨κ³4μ—μ„ νΈν–¥μ„± μ™„ν™” λ°©λ²• ν†µν•©',
      keyPoints: ['Attention λ©”μ»¤λ‹μ¦ μ΅°μ •', 'Debiasing layer μ¶”κ°€', 'Fairness constraints'],
      createdAt: new Date('2024-01-01T10:05:00'),
      updatedAt: new Date('2024-01-01T10:06:00'),
      charts: [
        {
          type: 'table',
          content: [['λ°©λ²•', 'ν¨κ³Ό'], ['Debiasing Layer', '85%'], ['Fairness Constraint', '72%']]
        }
      ],
      messages: [
        {
          id: 'm9',
          content: 'νΈν–¥μ„± λ¬Έμ μ™€ Transformer μ•„ν‚¤ν…μ²λ¥Ό ν•¨κ» κ³ λ ¤ν•λ©΄, λ¨λΈ μ„¤κ³„ λ‹¨κ³„μ—μ„λ¶€ν„° κ³µμ •μ„±μ„ λ°μν•  μ μμµλ‹λ‹¤.',
          role: 'assistant',
          branchId: 'merge1',
          timestamp: new Date('2024-01-01T10:05:00'),
        },
        {
          id: 'm10',
          content: 'Attention λ©”μ»¤λ‹μ¦μ„ μ΅°μ •ν•μ—¬ νΉμ • νΈν–¥μ„ μ™„ν™”ν•  μ μλ” λ°©λ²•μ΄ μμ„κΉμ”?',
          role: 'user',
          branchId: 'merge1',
          timestamp: new Date('2024-01-01T10:06:00'),
        },
      ],
    },
    {
      id: 'implementation',
      parentId: 'merge1',
      title: 'μ‹¤μ  κµ¬ν„ λ°©μ•',
      description: 'νΈν–¥ μ™„ν™” κΈ°μ  κµ¬ν„',
      type: 'solution',
      status: 'active',
      depth: 4,
      color: '#795548',
      messages: [
        {
          id: 'm11',
          content: 'λ‹¤μκ³Ό κ°™μ€ κµ¬μ²΄μ μΈ κµ¬ν„ λ°©μ•μ„ μ μ•ν•©λ‹λ‹¤:\n\n1. Debiasing Layer μ¶”κ°€\n2. Fairness Constraint μ μ©\n3. Balanced Training Data κµ¬μ„±',
          role: 'assistant',
          branchId: 'implementation',
          timestamp: new Date('2024-01-01T10:07:00'),
        },
      ],
    },
    {
      id: 'merge2',
      parentId: null,
      sourceNodeIds: ['privacy', 'optimization'],
      title: 'ν”„λΌμ΄λ²„μ‹ λ³΄νΈ μµμ ν™”',
      description: 'κ°μΈμ •λ³΄λ¥Ό λ³΄νΈν•λ©΄μ„ μ„±λ¥ μµμ ν™”',
      type: 'summary',
      status: 'paused',
      depth: 3,
      color: '#9E9E9E',
      isSummary: true,
      messages: [],
    },
  ]
  
  return nodes
}

// νΈν™μ„±μ„ μ„ν• λ³„μΉ­
export const generateDummyBranches = generateDummyNodes

export const getDefaultEdgeLabels = (): EdgeLabels => ({
  'root-ethics': 'μ¤λ¦¬μ  κ΄€μ ',
  'root-technical': 'κΈ°μ μ  κ΄€μ ',
  'ethics-bias': 'νΈν–¥μ„± νƒκµ¬',
  'ethics-privacy': 'ν”„λΌμ΄λ²„μ‹ μ΄μ',
  'technical-transformer': 'μ•„ν‚¤ν…μ² λ¶„μ„',
  'technical-optimization': 'μµμ ν™” λ°©λ²•',
  'bias-merge1': 'νΈν–¥ μ™„ν™” μ μ©',
  'transformer-merge1': 'κΈ°μ  κµ¬ν„',
  'merge1-implementation': 'μ‹¤μ  μ μ©',
})

function getDummyMarkdownContent(): string {
  return `# AI μ¤λ¦¬μ™€ κΈ°μ  κµ¬ν„ κ°€μ΄λ“

## π“‹ μ£Όμ” λ…Όμ 

AI μ‹μ¤ν… κ°λ° μ‹ κ³ λ ¤ν•΄μ•Ό ν•  **ν•µμ‹¬ μ”μ†λ“¤**:

1. **μ¤λ¦¬μ  κ³ λ ¤μ‚¬ν•­**
   - ν¬λ…μ„±κ³Ό μ„¤λ…κ°€λ¥μ„±
   - κ³µμ •μ„±κ³Ό νΈν–¥ μ κ±°
   - ν”„λΌμ΄λ²„μ‹ λ³΄νΈ

2. **κΈ°μ μ  κµ¬ν„**
   - μ•μ „ν• AI μ•„ν‚¤ν…μ²
   - λ¨λ‹ν„°λ§ μ‹μ¤ν…
   - κ°μ‚¬ λ΅κΉ…

## π’» μ½”λ“ μμ‹

### PythonμΌλ΅ κµ¬ν„ν• μ¤λ¦¬μ  AI μ‹μ¤ν…

\`\`\`python
import numpy as np
from typing import Dict, List
from datetime import datetime

class EthicalAIFramework:
    """μ¤λ¦¬μ  AI μμ‚¬κ²°μ • ν”„λ μ„μ›ν¬"""
    
    def __init__(self, transparency_threshold: float = 0.85):
        self.transparency = transparency_threshold
        self.audit_log = []
        self.bias_checker = BiasDetector()
    
    def process_decision(self, input_data: Dict) -> Dict:
        # 1. μ…λ ¥ κ²€μ¦
        validated_input = self.validate_input(input_data)
        
        # 2. νΈν–¥μ„± κ²€μ‚¬
        bias_score = self.bias_checker.check(validated_input)
        if bias_score > 0.3:
            return {"status": "rejected", "reason": "bias_detected"}
        
        # 3. AI λ¨λΈ μ‹¤ν–‰
        result = self.run_model(validated_input)
        
        # 4. κ°μ‚¬ λ΅κΉ…
        self.log_decision(input_data, result)
        
        return result
    
    def generate_explanation(self, decision_id: str) -> str:
        """μμ‚¬κ²°μ •μ— λ€ν• μ„¤λ… μƒμ„±"""
        decision = self.get_decision(decision_id)
        return f"Decision based on {len(decision['factors'])} factors..."
\`\`\`

## π”„ μ‹μ¤ν… μ•„ν‚¤ν…μ²

\`\`\`mermaid
graph TB
    subgraph "μ…λ ¥ κ³„μΈµ"
        A[μ‚¬μ©μ μ…λ ¥] --> B[λ°μ΄ν„° κ²€μ¦]
        B --> C{κ°μΈμ •λ³΄ ν¬ν•¨?}
    end
    
    subgraph "μ²λ¦¬ κ³„μΈµ"
        C -->|Yes| D[μµλ…ν™” μ²λ¦¬]
        C -->|No| E[μ§μ ‘ μ²λ¦¬]
        D --> F[AI λ¨λΈ]
        E --> F
        F --> G{νΈν–¥μ„± κ²€μ‚¬}
    end
    
    subgraph "μ¶λ ¥ κ³„μΈµ"
        G -->|ν†µκ³Ό| H[κ²°κ³Ό μƒμ„±]
        G -->|μ‹¤ν¨| I[μ¬μ²λ¦¬/κ±°λ¶€]
        H --> J[κ°μ‚¬ λ΅κ·Έ]
        I --> J
        J --> K[μµμΆ… μ¶λ ¥]
    end
    
    style A fill:#e1f5fe
    style K fill:#c8e6c9
    style I fill:#ffcdd2
\`\`\`

## π“ μ„±λ¥ λ©”νΈλ¦­

| λ©”νΈλ¦­ | λ©ν‘κ°’ | ν„μ¬κ°’ | μƒνƒ |
|--------|--------|--------|------|
| μ •ν™•λ„ | > 95% | 96.2% | β… |
| κ³µμ •μ„± μ§€μ | > 0.9 | 0.87 | β οΈ |
| ν¬λ…μ„± μ μ | > 85% | 88% | β… |
| μ‘λ‹µ μ‹κ°„ | < 100ms | 82ms | β… |

## π” SQL λ¨λ‹ν„°λ§ μΏΌλ¦¬

\`\`\`sql
-- μΌμΌ νΈν–¥μ„± λ¶„μ„ λ¦¬ν¬νΈ
WITH daily_metrics AS (
    SELECT 
        DATE(timestamp) as date,
        demographic_group,
        AVG(decision_score) as avg_score,
        COUNT(*) as decision_count,
        STDDEV(decision_score) as score_variance
    FROM ai_decisions
    WHERE timestamp >= NOW() - INTERVAL '7 days'
    GROUP BY DATE(timestamp), demographic_group
)
SELECT 
    date,
    demographic_group,
    avg_score,
    decision_count,
    ROUND(score_variance, 2) as variance,
    CASE 
        WHEN ABS(avg_score - 0.5) > 0.1 THEN 'β οΈ νΈν–¥ μ„ν—'
        ELSE 'β… μ •μƒ'
    END as status
FROM daily_metrics
ORDER BY date DESC, demographic_group;
\`\`\`

> π’΅ **ν**: μ΄λ¬ν• μ‹μ¤ν…μ€ μ§€μ†μ μΈ λ¨λ‹ν„°λ§κ³Ό κ°μ„ μ΄ ν•„μ”ν•©λ‹λ‹¤. μ •κΈ°μ μΌλ΅ λ©”νΈλ¦­μ„ κ²€ν† ν•κ³  ν•„μ”μ‹ λ¨λΈμ„ μ¬ν•™μµμ‹ν‚¤μ„Έμ”.

---

*κ° λ°©ν–¥μΌλ΅ λ” κΉμ΄ νƒκµ¬ν•μ‹κ² μµλ‹κΉ?*`
}